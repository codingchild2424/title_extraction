{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "good_test_folder_path = \"/workspace/home/uglee/Projects/title_extraction/datasets/raw_datasets/good_text_folder\"\n",
    "\n",
    "header_list = [\n",
    "    \"좋은시,좋은글,좋은말,이야기,삶,훈화\",\n",
    "    \"재미/유머,콩트,웃긴대사/장면,심리테스트\", \n",
    "    \"소설,단편,수필,편지,일기\",\n",
    "    \"서평/독후감,영화감상,여행일기\",\n",
    "    \"국내유명연설문,해외유명연설문\"\n",
    "    ]\n",
    "\n",
    "for idx, file in enumerate(os.listdir(good_test_folder_path)):\n",
    "\n",
    "    file_path = os.path.join(good_test_folder_path, file)\n",
    "\n",
    "    f = open(file_path, encoding='utf-8')\n",
    "\n",
    "    text = f.read()\n",
    "\n",
    "    if text in header_list:\n",
    "        print(file_path, \"remove\")\n",
    "        os.remove(file_path)\n",
    "        f.close()\n",
    "    else:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_clearner = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "\n",
    "for idx, file in enumerate(os.listdir(good_test_folder_path)):\n",
    "\n",
    "    file_path = os.path.join(good_test_folder_path, file)\n",
    "\n",
    "    f = open(file_path, encoding='utf-8')\n",
    "\n",
    "    text = f.read()\n",
    "\n",
    "    # HTML 제거\n",
    "    clean_text = BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "    # \\n 으로 쪼개기\n",
    "    clean_text_list = clean_text.split('\\n')\n",
    "\n",
    "    title = clean_text_list[0]\n",
    "    content = '\\n'.join(clean_text_list[1:])\n",
    "\n",
    "    # 데이터 전처리\n",
    "    title = title.replace(\"\\t\", \"\")\n",
    "    title = title.replace(\"\\n\", \" \")\n",
    "    title = title.replace(\"|\", \"\")\n",
    "\n",
    "    content = content.replace(\"\\t\", \"\")\n",
    "    content = content.replace(\"\\n\", \" \")\n",
    "    content = content.replace(\"|\", \"\")\n",
    "\n",
    "    title_content = title + \"\\t\" + content\n",
    "\n",
    "    file_name = file.split('.')[0]\n",
    "\n",
    "    tsv_path = os.path.join(good_test_folder_path, file_name + \".tsv\")\n",
    "\n",
    "    f = open(tsv_path, 'w', encoding='utf-8')\n",
    "\n",
    "    #print(idx, title_content)\n",
    "\n",
    "    f.write(title_content)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # if idx == 100:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file_list = []\n",
    "\n",
    "for file in os.listdir(good_test_folder_path):\n",
    "\n",
    "    tsv_file_name = file.split('.')[0] + \".tsv\"\n",
    "\n",
    "    tsv_file_list.append(tsv_file_name)\n",
    "\n",
    "#print(tsv_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error 여부 확인\n",
    "import pandas as pd\n",
    "\n",
    "for idx, tsv_file in enumerate(tsv_file_list):\n",
    "\n",
    "    tsv_file_path = os.path.join(good_test_folder_path, tsv_file)\n",
    "\n",
    "    df = pd.read_csv(tsv_file_path, sep=\"\\t\")\n",
    "\n",
    "    #print(\"shape: \", df.shape)\n",
    "\n",
    "    if df.shape != (0, 2):\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 폴더로 넘기기\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_clearner = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "\n",
    "for idx, file in enumerate(os.listdir(good_test_folder_path)):\n",
    "\n",
    "    file_path = os.path.join(good_test_folder_path, file)\n",
    "\n",
    "    f = open(file_path, encoding='utf-8')\n",
    "\n",
    "    text = f.read()\n",
    "\n",
    "    # HTML 제거\n",
    "    clean_text = BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "    # \\n 으로 쪼개기\n",
    "    clean_text_list = clean_text.split('\\n')\n",
    "\n",
    "    title = clean_text_list[0]\n",
    "    content = '\\n'.join(clean_text_list[1:])\n",
    "\n",
    "    # 데이터 전처리\n",
    "    title = title.replace(\"\\t\", \"\")\n",
    "    title = title.replace(\"\\n\", \" \")\n",
    "    title = title.replace(\"|\", \"\")\n",
    "\n",
    "    content = content.replace(\"\\t\", \"\")\n",
    "    content = content.replace(\"\\n\", \" \")\n",
    "    content = content.replace(\"|\", \"\")\n",
    "\n",
    "    title_content = title + \"\\t\" + content\n",
    "\n",
    "    file_name = file.split('.')[0]\n",
    "\n",
    "    tsv_path = os.path.join(\"/workspace/home/uglee/Projects/title_extraction/datasets/pre_datasets\", file_name + \".tsv\")\n",
    "\n",
    "    f = open(tsv_path, 'w', encoding='utf-8')\n",
    "\n",
    "    #print(idx, title_content)\n",
    "\n",
    "    f.write(title_content)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # if idx == 100:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
