{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['취미', '정치', '경제', '사건사고', '문화', '교육', 'IT_과학', '연예', '여성복지', '여행레저', '라이프스타일', '사회일발', '국제', '지역', '스포츠', '산업', '건강', '사회일반']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "raw_data_path = \"/workspace/home/uglee/Projects/title_extraction/datasets/raw_logical_datasets\"\n",
    "\n",
    "folder_list = os.listdir(raw_data_path)\n",
    "\n",
    "print(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_file_path = \"/workspace/home/uglee/Projects/title_extraction/datasets/raw_logical_datasets/건강/BWHE217000025083.json\"\n",
    "\n",
    "with open(test_file_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'설 예매 첫날 경부선 등 6개 노선 39만6000석 예매'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['named_entity'][0]['title'][0]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인터넷 예매대상 좌석수는 70만3000석이며 예매율은 56.3%로 지난해 추석 인터넷 예매 58.8%보다 2.5% 감소, 설 인터넷 예매보다 4.8% 증가했다..'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['named_entity'][0]['content'][0]['sentence']\n",
    "data['named_entity'][0]['content'][1]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content 코레일은 설 연휴기간 예매 첫날인 7일 경부·경전·충북·경북·대구·동해남부선 승차권의 오전 6시부터 오전 8시까지 2시간 동안 인터넷 예매 결과를 발표했다..인터넷 예매대상 좌석수는 70만3000석이며 예매율은 56.3%로 지난해 추석 인터넷 예매 58.8%보다 2.5% 감소, 설 인터넷 예매보다 4.8% 증가했다..노선별 예매율은 경부선 61.1%, 경전선 50.5%, 기타선 12.2%로 나타났으며, 열차종별 예매율은 ktx가 63.1%, 일반열차가 41.2%였다..코레일 관계자는 “이번 설 예매부터 기존에 오전 6시부터 9시까지였던 인터넷 예매시간을 오전 6시부터 오후 6시까지로 대폭 확대했다”며 “열차별 잔여석 조회예매도 가능토록 개선했다”고 설명했다..인터넷 동시 접속자(대기자) 수는 순간 최대 42만명으로 지난해 설 42만명과 같은 수준이었고, 추석 55만명보다는 13만명 감소했다..코레일은 인터넷 예매시작 직후 일시에 몰리면서 발생되는 고객 불편을 (이름)하기 위해 ▲대량접속 솔루션 증설(2대→8대) ▲웹서버 증설(평시 11대→37대) ▲예약발매 cpu 증설(96코어→136코어)로 전산시스템을 대폭 확충했다..예매 2일차인 8일에는 철도역과 지정된 대리점에서 경부·경전·충북·경북·대구·동해남부선 승차권 예매를 시행한다.시간은 오전 7시부터 오전 9시까지다..(이름) 코레일 사장은 “전산시스템 성능강화를 위해 대량접속 솔루션 서버를 2대에서 8대로 확충했다”며 “지난해 9월부터 사전 테스트를 시행한 결과 예매가 안정적으로 진행됐다”고 말했다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title = data['named_entity'][0]['title'][0]['sentence']\n",
    "content = [ dict['sentence'] for dict in data['named_entity'][0]['content']]\n",
    "\n",
    "content = ''.join(content)\n",
    "\n",
    "print(\"content\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3214/3214 [00:44<00:00, 71.86it/s]\n",
      "100%|██████████| 3714/3714 [00:55<00:00, 66.90it/s]\n",
      "100%|██████████| 5568/5568 [01:08<00:00, 81.33it/s]\n",
      "100%|██████████| 3193/3193 [00:41<00:00, 76.27it/s]\n",
      "100%|██████████| 1990/1990 [00:27<00:00, 72.77it/s]\n",
      "100%|██████████| 3126/3126 [00:38<00:00, 81.24it/s]\n",
      "100%|██████████| 1382/1382 [00:23<00:00, 58.85it/s]\n",
      "100%|██████████| 5323/5323 [01:08<00:00, 77.75it/s]\n",
      "100%|██████████| 3092/3092 [00:35<00:00, 86.06it/s]\n",
      "100%|██████████| 3607/3607 [00:48<00:00, 74.24it/s]\n",
      "100%|██████████| 3334/3334 [00:42<00:00, 78.90it/s]\n",
      "100%|██████████| 3474/3474 [00:43<00:00, 79.73it/s]\n",
      "100%|██████████| 2474/2474 [00:33<00:00, 73.59it/s]\n",
      "100%|██████████| 3655/3655 [00:42<00:00, 85.89it/s]\n",
      "100%|██████████| 2881/2881 [00:41<00:00, 69.43it/s]\n",
      "100%|██████████| 4552/4552 [01:02<00:00, 72.42it/s]\n",
      "100%|██████████| 3820/3820 [00:43<00:00, 88.45it/s]\n",
      "100%|██████████| 598/598 [00:06<00:00, 95.03it/s]\n",
      "100%|██████████| 18/18 [12:48<00:00, 42.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "pre_logical_datasets_path = \"/workspace/home/uglee/Projects/title_extraction/datasets/pre_logical_datasets\"\n",
    "\n",
    "for idx, folder in enumerate(tqdm(folder_list)):\n",
    "\n",
    "    json_folder_path = os.path.join(raw_data_path, folder)\n",
    "\n",
    "    for json_file in tqdm(os.listdir(json_folder_path)):\n",
    "        json_file_path = os.path.join(json_folder_path, json_file)\n",
    "\n",
    "        # json file 하나 가져오기\n",
    "        with open(json_file_path) as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "            # json file\n",
    "            for idx2, json_dict in enumerate(json_data['named_entity']):\n",
    "                try:\n",
    "                    title = json_dict['title'][0]['sentence']\n",
    "                    content = [ dict['sentence'] for dict in json_dict['content']]\n",
    "                    content = ''.join(content)\n",
    "\n",
    "                    title = title.replace(\"\\t\", \"\")\n",
    "                    title = title.replace(\"\\n\", \" \")\n",
    "\n",
    "                    # preprocessing title, erase ( ), [ ] and inside text in the (), []\n",
    "                    # use regex\n",
    "                    title = re.sub(r'\\([^)]*\\)', '', title)\n",
    "                    title = re.sub(r'\\[[^)]*\\]', '', title)\n",
    "\n",
    "                    # preprocess title, erase all the special characters\n",
    "                    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "\n",
    "                    # preprocess title with strip for removing the leading and trailing spaces\n",
    "                    title = title.strip()\n",
    "\n",
    "                    content = content.replace(\"\\t\", \"\")\n",
    "                    content = content.replace(\"\\n\", \" \")\n",
    "\n",
    "                    title_content = title + \"\\t\" + content\n",
    "\n",
    "                    tsv_file_name = \"logical\" + str(idx) + \"_\" + str(idx2) + \".tsv\"\n",
    "\n",
    "                    tsv_file_path = os.path.join(pre_logical_datasets_path, tsv_file_name)\n",
    "\n",
    "                    if os.path.isdir(tsv_file_path):\n",
    "                        continue\n",
    "                    else:\n",
    "                        f_json = open(tsv_file_path, 'w', encoding='utf-8')\n",
    "\n",
    "                        f_json.write(title_content)\n",
    "\n",
    "                        f_json.close()\n",
    "                except:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
